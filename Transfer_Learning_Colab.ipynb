""" Projeto: Treinamento de Redes Neurais com Transfer Learning (Colab) Autor: Gerado por ChatGPT (Sérgio: personalize como quiser) Descrição:

Notebook/script pronto para rodar no Google Colab.

Aplica Transfer Learning usando um backbone pré-treinado (MobileNetV2 / EfficientNetB0) e treina um classificador para duas classes (ex: gatos vs cachorros ou suas próprias classes).

Suporta dataset em pastas (ImageFolder style) ou carregamento via tfds.

Exporta modelo final, plots de loss/accuracy, e arquivo requirements.txt sugerido.


Como usar (resumo):

1. Abra este arquivo em Colab (File -> New Python 3 notebook -> paste) ou carregue no GitHub e abra via Colab.


2. Monte o Google Drive se for usar dados do Drive.


3. Prepare seus dados em uma pasta com a estrutura: dataset/ train/ class_A/... class_B/... val/ class_A/... class_B/...


4. Execute as células em ordem. Ajuste hiperparâmetros conforme necessário.



Observação: o script é escrito para rodar em ambientes com e sem GPU. No Colab selecione Runtime -> Change runtime type -> GPU. """

======= Configurações iniciais ==================================================

Versões recomendadas: tensorflow>=2.10.0, matplotlib, numpy, scikit-learn

import os import math import zipfile from datetime import datetime

import numpy as np import matplotlib.pyplot as plt import tensorflow as tf from tensorflow import keras from tensorflow.keras import layers

Reproducibilidade (não garante determinismo total em GPUs)

SEED = 42 tf.random.set_seed(SEED) np.random.seed(SEED)

======= CONFIGURÁVEIS DO PROJETO ==============================================

Caminho para o dataset (pasta com subpastas por classe)

No Colab, monte o Drive e ajuste: DATASET_DIR = '/content/drive/MyDrive/datasets/cats_and_dogs'

DATASET_DIR = '/content/dataset'

Se você tiver um arquivo zip com o dataset, defina aqui e o script irá extrair

DATASET_ZIP = ''  # ex: '/content/drive/MyDrive/dataset.zip' ou '' para não usar

Estrutura de pastas esperada (padrão ImageNet-style): dataset/train/<class>/, dataset/val/<class>/

TRAIN_DIR = os.path.join(DATASET_DIR, 'train') VAL_DIR = os.path.join(DATASET_DIR, 'val')

IMG_SIZE = (224, 224)    # pode usar (160,160) para MobileNetV2 ou 224 para EfficientNetB0 BATCH_SIZE = 32 NUM_CLASSES = None  # detectado automaticamente BACKBONE = 'MobileNetV2'  # opções: 'MobileNetV2', 'EfficientNetB0' FREEZE_BACKBONE = True FINE_TUNE_AT = None  # se None, não faz fine-tune; se int, desbloqueia últimos layers a partir desse index EPOCHS = 10 LEARNING_RATE = 1e-3 FINE_TUNE_LEARNING_RATE = 1e-5 OUTPUT_DIR = '/content/output' os.makedirs(OUTPUT_DIR, exist_ok=True)

Callbacks

early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True)

======= Helper: extrair zip se fornecido ======================================

if DATASET_ZIP: print('Extraindo dataset:', DATASET_ZIP) with zipfile.ZipFile(DATASET_ZIP, 'r') as z: z.extractall('/content') print('Extraído.')

======= Carregar dataset usando image_dataset_from_directory ==================

Se não existir pasta val, usamos validation_split

if os.path.exists(TRAIN_DIR) and os.path.exists(VAL_DIR): print('Carregando dataset a partir de duas pastas (train/ e val/)') train_ds = tf.keras.preprocessing.image_dataset_from_directory( TRAIN_DIR, labels='inferred', label_mode='int', batch_size=BATCH_SIZE, image_size=IMG_SIZE, shuffle=True, seed=SEED ) val_ds = tf.keras.preprocessing.image_dataset_from_directory( VAL_DIR, labels='inferred', label_mode='int', batch_size=BATCH_SIZE, image_size=IMG_SIZE, shuffle=False ) else: # tenta carregar a partir de uma pasta única e split print('Carregando dataset a partir de uma pasta única com split 80/20 (train/val)') if not os.path.exists(DATASET_DIR): raise FileNotFoundError(f"Diretório {DATASET_DIR} não encontrado. Faça upload do dataset no Colab ou ajuste DATASET_DIR.")

full_ds = tf.keras.preprocessing.image_dataset_from_directory(
    DATASET_DIR,
    labels='inferred',
    label_mode='int',
    batch_size=BATCH_SIZE,
    image_size=IMG_SIZE,
    shuffle=True,
    seed=SEED
)
# split manual por proporção
size = 0
for _ in full_ds.unbatch():
    size += 1
# OBS: calcular len(full_ds) é custoso; alternativa: usar tf.data and list files. Aqui usamos uma abordagem simples
all_images = list(full_ds.unbatch())
total = len(all_images)
val_count = int(total * 0.2)
train_count = total - val_count

# reconstruir datasets
imgs = [x[0].numpy() for x in all_images]
labels = [x[1].numpy() for x in all_images]
train_imgs = np.array(imgs[:train_count])
train_labels = np.array(labels[:train_count])
val_imgs = np.array(imgs[train_count:])
val_labels = np.array(labels[train_count:])

train_ds = tf.data.Dataset.from_tensor_slices((train_imgs, train_labels)).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)
val_ds = tf.data.Dataset.from_tensor_slices((val_imgs, val_labels)).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)

Detectar número de classes e nomes

class_names = train_ds.class_names if hasattr(train_ds, 'class_names') else None if class_names is None: # tentamos extrair a partir do primeiro batch for images, labels in train_ds.take(1): unique = np.unique(np.concatenate([labels.numpy().ravel()])) NUM_CLASSES = len(unique) break else: NUM_CLASSES = len(class_names)

print('Classes detectadas (NUM_CLASSES =', NUM_CLASSES, '):', class_names)

Prefetch e cache para performance (apenas se dados couberem em memória quando cache=True)

train_ds = train_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE) val_ds = val_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)

======= Data augmentation ====================================================

Usamos layers de Keras para aumentar dados on-the-fly

data_augmentation = keras.Sequential([ layers.RandomFlip('horizontal'), layers.RandomRotation(0.05), layers.RandomZoom(0.05), ], name='data_augmentation')

======= Build model com backbone pré-treinado ================================

input_shape = IMG_SIZE + (3,) inputs = layers.Input(shape=input_shape)

x = data_augmentation(inputs)

normalização - usar preprocess_input correspondente ao backbone

if BACKBONE == 'MobileNetV2': preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input base_model = tf.keras.applications.MobileNetV2(input_shape=input_shape, include_top=False, weights='imagenet') GLOBAL_POOL = layers.GlobalAveragePooling2D() elif BACKBONE == 'EfficientNetB0': preprocess_input = tf.keras.applications.efficientnet.preprocess_input base_model = tf.keras.applications.EfficientNetB0(input_shape=input_shape, include_top=False, weights='imagenet') GLOBAL_POOL = layers.GlobalAveragePooling2D() else: raise ValueError('BACKBONE desconhecido: use MobileNetV2 ou EfficientNetB0')

x = layers.Lambda(lambda img: preprocess_input(img))(x)

Congelar backbone inicialmente

base_model.trainable = not (not FREEZE_BACKBONE)  # True if not freezing if FREEZE_BACKBONE: base_model.trainable = False

x = base_model(x, training=False) x = GLOBAL_POOL(x) x = layers.Dropout(0.3)(x) outputs = layers.Dense(NUM_CLASSES, activation='softmax')(x)

model = keras.Model(inputs, outputs) model.summary()

======= Compile ==============================================================

model.compile( optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE), loss='sparse_categorical_crossentropy', metrics=['accuracy'] )

======= Treinamento inicial (com backbone congelado) =========================

history = model.fit( train_ds, epochs=EPOCHS, validation_data=val_ds, callbacks=[early_stop] )

======= Opcional: Fine-tuning =================================================

if FINE_TUNE_AT is not None: print('Descongelando o backbone a partir de:', FINE_TUNE_AT) base_model.trainable = True # Congela as camadas antes de FINE_TUNE_AT for layer in base_model.layers[:FINE_TUNE_AT]: layer.trainable = False

model.compile(
    optimizer=keras.optimizers.Adam(learning_rate=FINE_TUNE_LEARNING_RATE),
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

fine_tune_history = model.fit(
    train_ds,
    epochs=EPOCHS,
    validation_data=val_ds,
    callbacks=[early_stop]
)

======= Avaliação e plots ====================================================

Agrupa históricos se fine-tune foi usado

histories = [history] if 'fine_tune_history' in globals(): histories.append(fine_tune_history)

Função auxiliar para plotar

def plot_history(histories, out_dir=OUTPUT_DIR): plt.figure(figsize=(12, 5)) # Accuracy plt.subplot(1, 2, 1) for h in histories: plt.plot(h.history['accuracy']) for h in histories: plt.plot(h.history['val_accuracy'], '--') plt.title('Accuracy') plt.xlabel('Epoch') plt.ylabel('Accuracy') plt.legend(['train', 'val'] * len(histories))

# Loss
plt.subplot(1, 2, 2)
for h in histories:
    plt.plot(h.history['loss'])
for h in histories:
    plt.plot(h.history['val_loss'], '--')
plt.title('Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend(['train', 'val'] * len(histories))

fname = os.path.join(out_dir, f'training_history_{datetime.now().strftime("%Y%m%d_%H%M%S")}.png')
plt.tight_layout()
plt.savefig(fname)
print('Saved training plot to', fname)
plt.show()

plot_history(histories)

Avaliar no conjunto de validação

val_loss, val_acc = model.evaluate(val_ds) print(f'Validation loss: {val_loss:.4f}, accuracy: {val_acc:.4f}')

======= Matriz de confusão e classification report ===========================

coleta predições e labels

y_true = [] y_pred = [] for batch in val_ds: images, labels = batch preds = model.predict(images) y_true.extend(labels.numpy().ravel().tolist()) y_pred.extend(np.argmax(preds, axis=1).ravel().tolist())

from sklearn.metrics import confusion_matrix, classification_report cm = confusion_matrix(y_true, y_pred) print('Confusion matrix:\n', cm) print('Classification report:\n', classification_report(y_true, y_pred, target_names=class_names))

salva matriz de confusão como figura simples

plt.figure(figsize=(6, 6)) plt.imshow(cm, interpolation='nearest') plt.title('Confusion matrix') plt.colorbar() plt.xlabel('Predicted label') plt.ylabel('True label') plt.xticks(range(len(class_names)), class_names, rotation=45) plt.yticks(range(len(class_names)), class_names) plt.tight_layout() plt.savefig(os.path.join(OUTPUT_DIR, 'confusion_matrix.png')) plt.show()

======= Salvando o modelo ====================================================

model_path = os.path.join(OUTPUT_DIR, 'transfer_learning_model') model.save(model_path) print('Modelo salvo em', model_path)

======= Exportar requirements.txt (sugestão) =================================

requirements = [ 'tensorflow>=2.10.0', 'numpy', 'matplotlib', 'scikit-learn' ] with open(os.path.join(OUTPUT_DIR, 'requirements.txt'), 'w') as f: f.write('\n'.join(requirements)) print('requirements.txt salvo em', OUTPUT_DIR)

======= Dicas finais e próximos passos =======================================

- Ajuste IMG_SIZE, BATCH_SIZE e backbone conforme seu GPU/colab runtime.

- Experimente outras estratégias de augmentação e regularização.

- Para publicar no GitHub: crie um repositório, inclua este script/notebook, README.md, e um small sample do dataset ou links para download.

- Para subir o modelo e servir: salve em SavedModel ou converta para TFLite/ONNX conforme necessidade.

print('\nPronto!')

